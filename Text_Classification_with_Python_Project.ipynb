{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF3cTlYmPj-Q"
      },
      "source": [
        "# <font color='#2F4F4F'>AfterWork Data Science: Text Classification with Python - Project</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 1. Business Understading </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Research Question\n",
        "\n",
        "Build a text classification model that classifies a given text input as written in english or in dutch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "\n",
        "Build a classification model with an accuracy of score of atleast 85%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the Context \n",
        "\n",
        "You work as a Computational Linguist for a Global firm, collaborating with Engineers and\n",
        "Researchers in Assistant and Research & Machine Intelligence to develop language\n",
        "understanding models that improve our ability to understand and generate natural\n",
        "language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design\n",
        "\n",
        "* Business Understanding\n",
        "* Data Exploration\n",
        "* Data Preparation\n",
        "* Data Modeling and Evaluation\n",
        "* Summary of Findings \n",
        "* Recommendation\n",
        "* Challenges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtwSX1FmVPtw"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 2. Data Importation</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdQLGhWqVRTb",
        "outputId": "3c777e40-84fc-4f6c-b31e-fd223c3b3467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wordninja in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.0.0)\n",
            "Requirement already satisfied: textblob in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
            "Requirement already satisfied: regex in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.10.15)\n",
            "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.17.0)\n",
            "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.50.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# Importing the required libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd # library for data manipulation\n",
        "import numpy as np  # librariy for scientific computations\n",
        "import re           # regex library to perform text preprocessing\n",
        "import string       # library to work with strings\n",
        "import nltk         # library for natural language processing\n",
        "import scipy        # scientific computing \n",
        "import seaborn as sns # library for data visualisation\n",
        "\n",
        "# to display all columns\n",
        "pd.set_option('display.max.columns', None)\n",
        "\n",
        "# to display the entire contents of a cell\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Library for Stop words\n",
        "!pip3 install wordninja\n",
        "!pip3 install textblob\n",
        "import wordninja \n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Library for Lemmatization\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "\n",
        "# Library for Noun count\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Library for TD-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "\n",
        "# Library for metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i6Tr31PeCK0"
      },
      "outputs": [],
      "source": [
        "# Custom Functions\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Avg. words\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  try:\n",
        "    z = (sum(len(word) for word in words)/len(words))\n",
        "  except ZeroDivisionError:\n",
        "    z = 0 \n",
        "  return z\n",
        "\n",
        "# Noun count\n",
        "pos_dic = {\n",
        "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "    'adj' :  ['JJ','JJR','JJS'],\n",
        "    'adv' : ['RB','RBR','RBS','WRB']\n",
        "}\n",
        "\n",
        "def pos_check(x, flag):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "\n",
        "# Subjectivity \n",
        "def get_subjectivity(tweet):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(tweet, 'utf-8'))\n",
        "        subj = textblob.sentiment.subjectivity\n",
        "    except:\n",
        "        subj = 0.0\n",
        "    return subj\n",
        "\n",
        "# Polarity\n",
        "def get_polarity(tweet):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(tweet, 'utf-8'))\n",
        "        pol = textblob.sentiment.polarity\n",
        "    except:\n",
        "        pol = 0.0\n",
        "    return pol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taugd1WVVYBh",
        "outputId": "35c35d4d-c13f-46a7-d3d0-42e38996e2d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>Stockton, georiënteerde Route Highway nabij de Yuba State Red veel van de Highway die</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>The band released Reverberation to mostly negative reviews though the album has subsequently garnered some</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>advocacy gave the the dhamma.[87][88] or the central attracted most consolidated are 3rd the except</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>de juni naar stapte later verkaste optie was terug Sadlok jaar en dat wel Deze</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>During his House tenure Keating developed a reputation as a moderate on many issues which</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                            text  \\\n",
              "1063                       Stockton, georiënteerde Route Highway nabij de Yuba State Red veel van de Highway die   \n",
              "1020  The band released Reverberation to mostly negative reviews though the album has subsequently garnered some   \n",
              "230          advocacy gave the the dhamma.[87][88] or the central attracted most consolidated are 3rd the except   \n",
              "442                               de juni naar stapte later verkaste optie was terug Sadlok jaar en dat wel Deze   \n",
              "979                    During his House tenure Keating developed a reputation as a moderate on many issues which   \n",
              "\n",
              "     label  \n",
              "1063    nl  \n",
              "1020    en  \n",
              "230     en  \n",
              "442     nl  \n",
              "979     en  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loading and previewing the dataset\n",
        "df = pd.read_csv('http://bit.ly/EnglishNDutchDs') \n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKiQBwQuVd9k"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 3. Data Exploration</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKMZcfxGVo3m",
        "outputId": "a64b8a4c-1683-4091-cd81-901150c40f15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1069, 2)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check dataset shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8s9wj4_Vo3r"
      },
      "source": [
        "Our dataset has 1069 records and 2 variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ov8nTc9cVo3t",
        "outputId": "ebb5178e-627d-459c-f727-4c6027ac6705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     object\n",
              "label    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preview variable datatypes\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COOwPNRPVo3w"
      },
      "source": [
        "Both variables have the data type object. This is fine for the text variable, however for the label, we will need to convert it to a numerical format. We will do this later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE7Ik7ox85g6",
        "outputId": "128f945d-e41d-4b19-e087-b7003ca0eff6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plotting the distribution of label\n",
        "# ---\n",
        "#\n",
        "sns.countplot(df['label']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv9z0csQX5C9",
        "outputId": "65d7a622-83d5-4a38-a154-0c9a26ffd894"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nl    535\n",
              "en    534\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABx4lS8HZDxp"
      },
      "source": [
        "From above, we can see that our dataset is unbalanced thus we will need to sample equal no. of records for each label during data preparation to make a balanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNbvIvnT7ep"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 4. Data Preparation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbEEtXuWXuo"
      },
      "source": [
        "### <font color='#2F4F4F'>3.1 Data Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLde07_NVo3w",
        "outputId": "5ff140bd-cea6-4b48-8adf-39482971f49c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check for duplicates\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY9eV5l6V_Xv"
      },
      "source": [
        "There are 10 duplicates. We will need to drop these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQLb6TqVVo3z",
        "outputId": "90c04af7-f2ee-4f6a-9733-5dc7789e5297"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check for missing values\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npaYUA7bVo33"
      },
      "source": [
        "No missing values found. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZGm8pnHWGrb",
        "outputId": "01e9200c-8f63-42ea-a870-89c796c83d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1059, 2)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dropping our duplicates\n",
        "df = df.drop_duplicates()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0IQmdGugKGF",
        "outputId": "f51aa5f9-7af5-4602-f90e-4b49435db2a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['en', 'nl'], dtype=object)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What values are in our label variable?\n",
        "# ---\n",
        "#\n",
        "df.label.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzZsUs0FZDRU",
        "outputId": "2e9222c5-5801-4afb-cc6c-5034a5c760cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The Apostolic Prefecture of Shiqian Shihtsien is a Latin prediocesan missionary jurisdiction of the Catholic</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>He played for Indian Super League club Pune City in before returning to Charlton in</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>Each cartoon written by Calveley and directed by Bob Godfrey was about five minutes long</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>reddish bark and the smaller twigs sometimes have bristly glandular hairs. The leaves are shiny</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>left upon artisans and north-western own India society nomadic and the north.[104][105] raising vast to</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                             text  \\\n",
              "996  The Apostolic Prefecture of Shiqian Shihtsien is a Latin prediocesan missionary jurisdiction of the Catholic   \n",
              "865                           He played for Indian Super League club Pune City in before returning to Charlton in   \n",
              "948                      Each cartoon written by Calveley and directed by Bob Godfrey was about five minutes long   \n",
              "542               reddish bark and the smaller twigs sometimes have bristly glandular hairs. The leaves are shiny   \n",
              "244       left upon artisans and north-western own India society nomadic and the north.[104][105] raising vast to   \n",
              "\n",
              "    label  \n",
              "996    en  \n",
              "865    en  \n",
              "948    en  \n",
              "542    en  \n",
              "244    en  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sampling text with en \n",
        "df_en = df[df[\"label\"] == 'en'] \n",
        "df_en = df_en.sample(200)\n",
        "\n",
        "# sampling text with nl \n",
        "df_nl = df[df[\"label\"] == 'nl'] \n",
        "df_nl = df_nl.sample(200)\n",
        "\n",
        "# combining our dataframes\n",
        "df = pd.concat([df_en, df_nl])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu0mUgQgfNxE",
        "outputId": "7ea5b26d-eb49-4884-d308-40792cef6ae8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "en    200\n",
              "nl    200\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABEvQqbfXHF"
      },
      "source": [
        "We now have our balanced dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueIz-A-eWga9"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.2 Text Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK2JdNP3ogmP",
        "outputId": "1f0d5cf7-a0a6-4d44-b4b5-aecc934640f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The Apostolic Prefecture of Shiqian Shihtsien is a Latin prediocesan missionary jurisdiction of the Catholic</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>He played for Indian Super League club Pune City in before returning to Charlton in</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>Each cartoon written by Calveley and directed by Bob Godfrey was about five minutes long</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>reddish bark and the smaller twigs sometimes have bristly glandular hairs. The leaves are shiny</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>left upon artisans and north-western own India society nomadic and the north.[104][105] raising vast to</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                             text  \\\n",
              "996  The Apostolic Prefecture of Shiqian Shihtsien is a Latin prediocesan missionary jurisdiction of the Catholic   \n",
              "865                           He played for Indian Super League club Pune City in before returning to Charlton in   \n",
              "948                      Each cartoon written by Calveley and directed by Bob Godfrey was about five minutes long   \n",
              "542               reddish bark and the smaller twigs sometimes have bristly glandular hairs. The leaves are shiny   \n",
              "244       left upon artisans and north-western own India society nomadic and the north.[104][105] raising vast to   \n",
              "\n",
              "    label  \n",
              "996    en  \n",
              "865    en  \n",
              "948    en  \n",
              "542    en  \n",
              "244    en  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = df.copy()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATi3KYKuWtJ5"
      },
      "outputs": [],
      "source": [
        "# We will create a custom function that will contain all the text cleaning \n",
        "# techniques. We can then reuse the same function for cleaning new data\n",
        "# without rewriting the code.\n",
        "# ---\n",
        "#\n",
        "def text_cleaning(txt):\n",
        "    txt = re.sub(r'#', '', txt)                   # Removing hashtags\n",
        "    txt = re.sub(r'@[A-Za-z0-9]+', '', txt)       # Removing Mentions\n",
        "    txt = re.sub(r'https?:\\/\\/\\S+', '', txt)      # Removing Links\n",
        "    txt = re.sub(r'RT[\\s]+', '', txt)             # Removing Retweets\n",
        "    txt = re.sub(r'\\n', ' ', txt)                 # Removing Newline\n",
        "    txt = re.sub(r\"[^a-zA-Z0-9]\",\" \", txt)        # Removing all special characters\n",
        "    return txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXhae-QrhX85",
        "outputId": "1f4c3215-8161-4292-bab4-2294457abc82"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The Apostolic Prefecture of Shiqian Shihtsien is a Latin prediocesan missionary jurisdiction of the Catholic</td>\n",
              "      <td>en</td>\n",
              "      <td>The Apostolic Prefecture of Shiqian Shihtsien is a Latin prediocesan missionary jurisdiction of the Catholic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>He played for Indian Super League club Pune City in before returning to Charlton in</td>\n",
              "      <td>en</td>\n",
              "      <td>He played for Indian Super League club Pune City in before returning to Charlton in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948</th>\n",
              "      <td>Each cartoon written by Calveley and directed by Bob Godfrey was about five minutes long</td>\n",
              "      <td>en</td>\n",
              "      <td>Each cartoon written by Calveley and directed by Bob Godfrey was about five minutes long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>reddish bark and the smaller twigs sometimes have bristly glandular hairs. The leaves are shiny</td>\n",
              "      <td>en</td>\n",
              "      <td>reddish bark and the smaller twigs sometimes have bristly glandular hairs  The leaves are shiny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>left upon artisans and north-western own India society nomadic and the north.[104][105] raising vast to</td>\n",
              "      <td>en</td>\n",
              "      <td>left upon artisans and north western own India society nomadic and the north  104  105  raising vast to</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                             text  \\\n",
              "996  The Apostolic Prefecture of Shiqian Shihtsien is a Latin prediocesan missionary jurisdiction of the Catholic   \n",
              "865                           He played for Indian Super League club Pune City in before returning to Charlton in   \n",
              "948                      Each cartoon written by Calveley and directed by Bob Godfrey was about five minutes long   \n",
              "542               reddish bark and the smaller twigs sometimes have bristly glandular hairs. The leaves are shiny   \n",
              "244       left upon artisans and north-western own India society nomadic and the north.[104][105] raising vast to   \n",
              "\n",
              "    label  \\\n",
              "996    en   \n",
              "865    en   \n",
              "948    en   \n",
              "542    en   \n",
              "244    en   \n",
              "\n",
              "                                                                                                         clean_en  \n",
              "996  The Apostolic Prefecture of Shiqian Shihtsien is a Latin prediocesan missionary jurisdiction of the Catholic  \n",
              "865                           He played for Indian Super League club Pune City in before returning to Charlton in  \n",
              "948                      Each cartoon written by Calveley and directed by Bob Godfrey was about five minutes long  \n",
              "542               reddish bark and the smaller twigs sometimes have bristly glandular hairs  The leaves are shiny  \n",
              "244       left upon artisans and north western own India society nomadic and the north  104  105  raising vast to  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Applying the text_cleaning function to our dataframe.\n",
        "# ---\n",
        "# NB: This process may take 5-10 min.\n",
        "# ---\n",
        "#\n",
        "df[\"clean_en\"] = df[\"text\"].apply(text_cleaning)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHzztFd5Wpx_"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.3 Feature Engineering</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91ZkaNK4Wth2"
      },
      "outputs": [],
      "source": [
        "# We will create a custom function that will contain all the \n",
        "# feature engineering techniques. We can then use this function \n",
        "# for cleaning new data. \n",
        "# ---\n",
        "#\n",
        "def custom_feature(feature):\n",
        "    ln = []\n",
        "    word = []\n",
        "    for i in feature:\n",
        "        ln.append(len(i))\n",
        "        word.append(len(i.split(\" \")))\n",
        "    \n",
        "    density = np.array(word)/np.array(ln)\n",
        "    return ln, word, density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dli-H5lNjESt"
      },
      "outputs": [],
      "source": [
        "# Applying the custom feature engineering function to our dataframe.\n",
        "# This process may take 2-5 min.\n",
        "# ---\n",
        "#\n",
        "ln, word, density = custom_feature(df.text)\n",
        "\n",
        "df[\"text_len\"] = ln\n",
        "df[\"words\"] = word\n",
        "df[\"density\"] = density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPUG6EiQjN3B"
      },
      "outputs": [],
      "source": [
        "# Performing further feature engineering techniques\n",
        "# ---\n",
        "#\n",
        "import textblob\n",
        "def get_subjectivity(text):\n",
        "    return textblob.TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "df[\"subjecttivity\"]=df.text.apply(get_subjectivity)\n",
        "\n",
        "# Feature Construction: Word Level N-Gram TF-IDF Feature \n",
        "# ---\n",
        "#\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer(ngram_range=(1, 1), max_features=2000)\n",
        "\n",
        "df_char_vect = vec.fit_transform(df.text)\n",
        "\n",
        "# Feature Construction: Character Level N-Gram TF-IDF \n",
        "# ---\n",
        "#\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer(ngram_range=(2, 2), max_features=2000)\n",
        "\n",
        "df_word_vect = vec.fit_transform(df.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU5dGj1_jO8B"
      },
      "outputs": [],
      "source": [
        "# Let's prepare the constructed features for modeling\n",
        "# ---\n",
        "# We will select all variables but the target (which is the label) and text variables \n",
        "# ---\n",
        "#  \n",
        "X_metadata = np.array(df.iloc[:, 3:7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8F3QQ6PjZsc"
      },
      "outputs": [],
      "source": [
        "# We combine our two tfidf (sparse) matrices and X_metadata\n",
        "# ---\n",
        "#\n",
        "X = scipy.sparse.hstack([df_word_vect, df_char_vect,  X_metadata]).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-YdQkYqoYjs"
      },
      "outputs": [],
      "source": [
        "# Label Preparation i.e. replacing categorial values with numerical ones\n",
        "# ---  \n",
        "#\n",
        "y = df.iloc[:, 1]\n",
        "y = np.array(y.replace({\"en\":0, \"nl\":1}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z58VpwHoasH_"
      },
      "source": [
        "##  <font color='#2F4F4F'>Step 5. Data Modeling</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKm33MJYasH_"
      },
      "source": [
        "We will carry out 10 types of classification analysis, namely:\n",
        "1.  Logistic Regression\n",
        "3.  Decision Trees Classification\n",
        "4.  Support Vector Machine (SVM) Classification\n",
        "5. K-Nearest Neighbors (KNN) Classification\n",
        "6.  Gaussian Naive Bayes (NB) Classification\n",
        "7.  BaggingClassifier\n",
        "8.  RandomForestClassifier\n",
        "9.  AdaBoostClassifier\n",
        "10. GradientBoostingClassifier\n",
        "\n",
        "We use their default parameters then compare the different classification models to assess the best performing one(s). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kByQ2gGOasIN"
      },
      "outputs": [],
      "source": [
        "# splitting into 80-20 train-test sets\n",
        "# ---\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3hBaXKTasIV",
        "outputId": "248c3a39-2b80-4547-ff0b-90a65c4b2a9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# loading our classification libraries\n",
        "# ---\n",
        "#\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "\n",
        "# instantiating our classifiers\n",
        "lg = LogisticRegression()\n",
        "nb = GaussianNB()\n",
        "dt = DecisionTreeClassifier()\n",
        "knn = KNeighborsClassifier()\n",
        "svc = SVC()\n",
        "rand = RandomForestClassifier()\n",
        "ada = AdaBoostClassifier()\n",
        "grad = GradientBoostingClassifier()\n",
        "bag = BaggingClassifier()\n",
        "\n",
        "# fitting our classifiers to the training data\n",
        "lg.fit(X_train, y_train)\n",
        "nb.fit(X_train, y_train)\n",
        "dt.fit(X_train, y_train)\n",
        "knn.fit(X_train, y_train)\n",
        "svc.fit(X_train, y_train)\n",
        "rand.fit(X_train, y_train)\n",
        "ada.fit(X_train, y_train)\n",
        "grad.fit(X_train, y_train)\n",
        "bag.fit(X_train, y_train)\n",
        "\n",
        "# making predictions\n",
        "pred_lg = lg.predict(X_test)\n",
        "pred_nb = nb.predict(X_test)\n",
        "pred_dt = dt.predict(X_test)\n",
        "pred_knn = knn.predict(X_test)\n",
        "pred_svc = svc.predict(X_test)\n",
        "pred_rand = rand.predict(X_test)\n",
        "pred_ada = ada.predict(X_test)\n",
        "pred_grad = grad.predict(X_test)\n",
        "pred_bag = bag.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfXCA87-asIf",
        "outputId": "f484dc7b-6e36-4cc0-9750-521cf08da8a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of LogisticRegression is          :  0.99\n",
            "Accuracy of GaussianNB is                  :  0.99\n",
            "Accuracy of DecisionTreeClassifier is      :  0.98\n",
            "Accuracy of KNeighborsClassifier is        :  0.6\n",
            "Accuracy of SVC is                         :  0.45\n",
            "Accuracy of RandomForestClassifier is      :  1.0\n",
            "Accuracy of AdaBoostClassifier is          :  0.99\n",
            "Accuracy of GradientBoostingClassifier is  :  0.98\n",
            "Accuracy of BaggingClassifier is           :  1.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the Models\n",
        "# ---\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Accuracy scores\n",
        "#\n",
        "print(\"Accuracy of LogisticRegression is          : \", round(accuracy_score(y_test, pred_lg), 2))\n",
        "print(\"Accuracy of GaussianNB is                  : \", round(accuracy_score(y_test, pred_nb), 2))\n",
        "print(\"Accuracy of DecisionTreeClassifier is      : \", round(accuracy_score(y_test, pred_dt), 2))\n",
        "print(\"Accuracy of KNeighborsClassifier is        : \", round(accuracy_score(y_test, pred_knn), 2))\n",
        "print(\"Accuracy of SVC is                         : \", round(accuracy_score(y_test, pred_svc), 2))\n",
        "print(\"Accuracy of RandomForestClassifier is      : \", round(accuracy_score(y_test, pred_rand), 2))\n",
        "print(\"Accuracy of AdaBoostClassifier is          : \", round(accuracy_score(y_test, pred_ada), 2))\n",
        "print(\"Accuracy of GradientBoostingClassifier is  : \", round(accuracy_score(y_test, pred_grad), 2))\n",
        "print(\"Accuracy of BaggingClassifier is           : \", round(accuracy_score(y_test, pred_bag), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ0H_nXpo-lK"
      },
      "source": [
        "Your observation about the performance of the models...\n",
        "\n",
        "From these accuracy we can see Except KNN and SVC all models are performing really well "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyF5hh38pu5F",
        "outputId": "123274c8-0edc-4202-b604-a0e7e7c9ab29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matric of LogisticRegression is          : \n",
            " [[44  0]\n",
            " [ 1 35]]\n",
            "Confusion matric of GaussianNB is                  : \n",
            " [[43  1]\n",
            " [ 0 36]]\n",
            "Confusion matric of DecisionTreeClassifier is      : \n",
            " [[42  2]\n",
            " [ 0 36]]\n",
            "Confusion matric of KNeighborsClassifier is        : \n",
            " [[25 19]\n",
            " [13 23]]\n",
            "Confusion matric of SVC is                         : \n",
            " [[ 0 44]\n",
            " [ 0 36]]\n",
            "Confusion matric of RandomForestClassifier is      : \n",
            " [[44  0]\n",
            " [ 0 36]]\n",
            "Confusion matric of AdaBoostClassifier is          : \n",
            " [[43  1]\n",
            " [ 0 36]]\n",
            "Confusion matric of GradientBoostingClassifier is  : \n",
            " [[42  2]\n",
            " [ 0 36]]\n",
            "Confusion matric of BaggingClassifier is           : \n",
            " [[44  0]\n",
            " [ 0 36]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrices\n",
        "# ---\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"Confusion matric of LogisticRegression is          : \\n\", confusion_matrix(y_test, pred_lg))\n",
        "print(\"Confusion matric of GaussianNB is                  : \\n\", confusion_matrix(y_test, pred_nb))\n",
        "print(\"Confusion matric of DecisionTreeClassifier is      : \\n\", confusion_matrix(y_test, pred_dt))\n",
        "print(\"Confusion matric of KNeighborsClassifier is        : \\n\", confusion_matrix(y_test, pred_knn))\n",
        "print(\"Confusion matric of SVC is                         : \\n\", confusion_matrix(y_test, pred_svc))\n",
        "print(\"Confusion matric of RandomForestClassifier is      : \\n\", confusion_matrix(y_test, pred_rand))\n",
        "print(\"Confusion matric of AdaBoostClassifier is          : \\n\", confusion_matrix(y_test, pred_ada))\n",
        "print(\"Confusion matric of GradientBoostingClassifier is  : \\n\", confusion_matrix(y_test, pred_grad))\n",
        "print(\"Confusion matric of BaggingClassifier is           : \\n\", confusion_matrix(y_test, pred_bag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBJJqpvjp_Nl",
        "outputId": "986a3706-3e45-473f-8096-69fe31a23e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report of LogisticRegression is          : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        44\n",
            "           1       1.00      0.97      0.99        36\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n",
            "Classification Report of GaussianNB is                  : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        44\n",
            "           1       0.97      1.00      0.99        36\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n",
            "Classification Report of DecisionTreeClassifier is      : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98        44\n",
            "           1       0.95      1.00      0.97        36\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.98      0.97        80\n",
            "weighted avg       0.98      0.97      0.98        80\n",
            "\n",
            "Classification Report of KNeighborsClassifier is        : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.57      0.61        44\n",
            "           1       0.55      0.64      0.59        36\n",
            "\n",
            "    accuracy                           0.60        80\n",
            "   macro avg       0.60      0.60      0.60        80\n",
            "weighted avg       0.61      0.60      0.60        80\n",
            "\n",
            "Classification Report of SVC is                         : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        44\n",
            "           1       0.45      1.00      0.62        36\n",
            "\n",
            "    accuracy                           0.45        80\n",
            "   macro avg       0.23      0.50      0.31        80\n",
            "weighted avg       0.20      0.45      0.28        80\n",
            "\n",
            "Classification Report of RandomForestClassifier is      : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        36\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "Classification Report of AdaBoostClassifier is          : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        44\n",
            "           1       0.97      1.00      0.99        36\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n",
            "Classification Report of GradientBoostingClassifier is  : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98        44\n",
            "           1       0.95      1.00      0.97        36\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.98      0.97        80\n",
            "weighted avg       0.98      0.97      0.98        80\n",
            "\n",
            "Classification Report of BaggingClassifier is           : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        36\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Classification Reports\n",
        "# ---\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "# \n",
        "print(\"Classification Report of LogisticRegression is          : \\n\", classification_report(y_test, pred_lg))\n",
        "print(\"Classification Report of GaussianNB is                  : \\n\", classification_report(y_test, pred_nb))\n",
        "print(\"Classification Report of DecisionTreeClassifier is      : \\n\", classification_report(y_test, pred_dt))\n",
        "print(\"Classification Report of KNeighborsClassifier is        : \\n\", classification_report(y_test, pred_knn))\n",
        "print(\"Classification Report of SVC is                         : \\n\", classification_report(y_test, pred_svc))\n",
        "print(\"Classification Report of RandomForestClassifier is      : \\n\", classification_report(y_test, pred_rand))\n",
        "print(\"Classification Report of AdaBoostClassifier is          : \\n\", classification_report(y_test, pred_ada))\n",
        "print(\"Classification Report of GradientBoostingClassifier is  : \\n\", classification_report(y_test, pred_grad))\n",
        "print(\"Classification Report of BaggingClassifier is           : \\n\", classification_report(y_test, pred_bag))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA28XDA03Q9-"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 6. Summary of Findings and Recommendation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASVijr_e3WF2"
      },
      "source": [
        "Your findings and recommendations...\n",
        "\n",
        "From this classification process of text I have observed that distance based models cannot perform well if your data is related to text. From accuracies we have seen that Except KNN and SVC all models are performing really well without any Hyperoarameter tuning. Both KNN and SVC are distance based model and are not performing well. That's mean for sequence data we can't use distance based model because they will not be performing well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI23jTyh5XDU"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 7. Challenging our Solution</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6HR28mq6mg5"
      },
      "source": [
        "### a) Did we have the right question?\n",
        "\n",
        "Yes\n",
        "\n",
        "### b) Did we have the right data?\n",
        "\n",
        "Yes, we have right data for our problem.\n",
        "### c) What can be done to improve the solution? \n",
        "\n",
        "Models are already performing very well so they don't need anything to improve but as we have seen that distance based models are not performing well for this data. We can test out different values of their hyperparameters to increase accuracy. But still they will be performing low than other models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kLG2VTrnTvYL",
        "XecOwPNorl2W",
        "J4wfHZwQrs-t",
        "a9BPYqunry97",
        "7KMRBJ7zr9HD",
        "UtwSX1FmVPtw",
        "JKiQBwQuVd9k",
        "dfbEEtXuWXuo",
        "H6HR28mq6mg5"
      ],
      "name": "Text Classification with Python - Project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}